{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../analysis_util')\n",
    "sys.path.append('../scrapers')\n",
    "from get_file_from_s3 import read_save_s3_files, Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_save_s3_files wallstreetbets\n",
      "author_data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-52d4c01a13ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m read_save_s3_files(file_names=['author_data', 'comment_data', 'submission_data', 'text_data'],\n\u001B[0m\u001B[1;32m      2\u001B[0m                    \u001B[0mbucket\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'wallstreetbets'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                    start_yyyymmdd=20211106)\n\u001B[1;32m      4\u001B[0m read_save_s3_files(file_names=['trend_data'],\n\u001B[1;32m      5\u001B[0m                    \u001B[0mbucket\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'googletrends'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/repos/6242-finance-project/scrapers/get_file_from_s3.py\u001B[0m in \u001B[0;36mread_save_s3_files\u001B[0;34m(bucket, file_names, force_continue, freq, start_yyyymmdd, start_hh, start_mm)\u001B[0m\n\u001B[1;32m     43\u001B[0m                         \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_or_buf\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mpath_to_save\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m                     \u001B[0mdata_temp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m                 \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m                     \u001B[0mj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'allow_redirects'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'get'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    528\u001B[0m         }\n\u001B[1;32m    529\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m         \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    641\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0;31m# Send the request\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 643\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    644\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    645\u001B[0m         \u001B[0;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mchunked\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 439\u001B[0;31m                 resp = conn.urlopen(\n\u001B[0m\u001B[1;32m    440\u001B[0m                     \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m                     \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    668\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    669\u001B[0m             \u001B[0;31m# Make the request on the httplib connection object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 670\u001B[0;31m             httplib_response = self._make_request(\n\u001B[0m\u001B[1;32m    671\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    379\u001B[0m         \u001B[0;31m# Trigger any extra validation we need to do.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 381\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_conn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    382\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m             \u001B[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_validate_conn\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m    974\u001B[0m         \u001B[0;31m# Force connect early to allow us to validate the connection.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    975\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"sock\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# AppEngine might not have  `.sock`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 976\u001B[0;31m             \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    977\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    978\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_verified\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\u001B[0m in \u001B[0;36mconnect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    306\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m         \u001B[0;31m# Add certificate verification\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 308\u001B[0;31m         \u001B[0mconn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_new_conn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    309\u001B[0m         \u001B[0mhostname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhost\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\u001B[0m in \u001B[0;36m_new_conn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 159\u001B[0;31m             conn = connection.create_connection(\n\u001B[0m\u001B[1;32m    160\u001B[0m                 \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dns_host\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mextra_kw\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    161\u001B[0m             )\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/connection.py\u001B[0m in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0msource_address\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m                 \u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_address\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m             \u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msa\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msock\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "read_save_s3_files(file_names=['author_data', 'comment_data', 'submission_data', 'text_data'],\n",
    "                   bucket='wallstreetbets',\n",
    "                   start_yyyymmdd=20211106)\n",
    "read_save_s3_files(file_names=['trend_data'],\n",
    "                   bucket='googletrends',\n",
    "                   start_yyyymmdd=20211114, freq=Freq.EVERY15MIN, force_continue=8, start_hh=6, start_mm=0)\n",
    "read_save_s3_files(file_names=['stock_data'],\n",
    "                   bucket='nasdaq',\n",
    "                   start_yyyymmdd=20211107, freq=Freq.EVERYDAY)\n",
    "read_save_s3_files(file_names=['author_data', 'comment_data', 'submission_data', 'text_data'],\n",
    "                   bucket='investing',\n",
    "                   start_yyyymmdd=20211110, start_hh=8)\n",
    "read_save_s3_files(file_names=['author_data', 'comment_data', 'submission_data', 'text_data'],\n",
    "                   bucket='stocks',\n",
    "                   start_yyyymmdd=20211110, start_hh=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate files into single pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_csv_to_dataframe(directory = 'wallstreetbets', sub_folder = ''):\n",
    "    # getting csv files from the folder MyProject\n",
    "    path = os.getcwd() + f'/output/{directory}'\n",
    "    if sub_folder != '':\n",
    "        path += f'/{sub_folder}'\n",
    "\n",
    "    print(path)\n",
    "    # read all the files with extension .csv\n",
    "    filenames = glob.glob(path + \"/*.csv\")\n",
    "    # print('File names:', filenames)\n",
    "\n",
    "    li = []\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0, lineterminator='\\r')\n",
    "            li.append(df)\n",
    "        except Exception as e:\n",
    "            print(filename)\n",
    "            \n",
    "    df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/googletrends/trend_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/googletrends/trend_data\\googletrends_trend_data_20211114_09_30.csv\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/googletrends/trend_data\\googletrends_trend_data_20211121_07_00.csv\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/googletrends/trend_data\\googletrends_trend_data_20211121_07_15.csv\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/wallstreetbets/author_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/wallstreetbets/comment_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/wallstreetbets/submission_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/wallstreetbets/text_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/investing/author_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/investing/comment_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/investing/submission_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/investing/text_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/stocks/author_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/stocks/comment_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/stocks/submission_data\n",
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/stocks/text_data\n"
     ]
    }
   ],
   "source": [
    "google_trends = load_csv_to_dataframe(directory = 'googletrends', sub_folder = 'trend_data')\n",
    "wb_author_data = load_csv_to_dataframe(directory = 'wallstreetbets', sub_folder = 'author_data')\n",
    "wb_comment_data = load_csv_to_dataframe(directory = 'wallstreetbets', sub_folder = 'comment_data')\n",
    "wb_submission_data = load_csv_to_dataframe(directory = 'wallstreetbets', sub_folder = 'submission_data')\n",
    "wb_text_data = load_csv_to_dataframe(directory = 'wallstreetbets', sub_folder = 'text_data')\n",
    "\n",
    "inv_author_data = load_csv_to_dataframe(directory = 'investing', sub_folder = 'author_data')\n",
    "inv_comment_data = load_csv_to_dataframe(directory = 'investing', sub_folder = 'comment_data')\n",
    "inv_submission_data = load_csv_to_dataframe(directory = 'investing', sub_folder = 'submission_data')\n",
    "inv_text_data = load_csv_to_dataframe(directory = 'investing', sub_folder = 'text_data')\n",
    "\n",
    "stk_author_data = load_csv_to_dataframe(directory = 'stocks', sub_folder = 'author_data')\n",
    "stk_comment_data = load_csv_to_dataframe(directory = 'stocks', sub_folder = 'comment_data')\n",
    "stk_submission_data = load_csv_to_dataframe(directory = 'stocks', sub_folder = 'submission_data')\n",
    "stk_text_data = load_csv_to_dataframe(directory = 'stocks', sub_folder = 'text_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Georgia Tech\\6242-finance-project\\notebooks/output/nasdaq/stock_data\n"
     ]
    }
   ],
   "source": [
    "stock_data = load_csv_to_dataframe(directory = 'nasdaq', sub_folder = 'stock_data')\n",
    "\n",
    "stock_data['update_dt'] = pd.to_datetime(stk_text_data['update_dt'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data = pd.concat([wb_author_data, inv_author_data, stk_author_data], axis=0, ignore_index=True)\n",
    "comment_data = pd.concat([wb_comment_data, inv_comment_data, stk_comment_data], axis=0, ignore_index=True)\n",
    "submission_data = pd.concat([wb_submission_data, inv_submission_data, stk_submission_data], axis=0, ignore_index=True)\n",
    "text_data = pd.concat([wb_text_data, inv_text_data, stk_text_data], axis=0, ignore_index=True)\n",
    "text_data.dropna(subset = ['id', 'type', 'text', 'update_dt'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data['created_utc'] = pd.to_datetime(author_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "author_data['update_dt'] = pd.to_datetime(author_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "comment_data['created_utc'] = pd.to_datetime(comment_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "comment_data['update_dt'] = pd.to_datetime(comment_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "submission_data['created_utc'] = pd.to_datetime(submission_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "submission_data['update_dt'] = pd.to_datetime(submission_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "text_data['update_dt'] = pd.to_datetime(text_data['update_dt'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_data (22988, 10)\n",
      "comment_data (20306, 7)\n",
      "submission_data (2755, 7)\n",
      "text_data (25597, 4)\n"
     ]
    }
   ],
   "source": [
    "print('author_data', author_data.shape)\n",
    "print('comment_data', comment_data.shape)\n",
    "print('submission_data', submission_data.shape)\n",
    "print('text_data', text_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     author_id name is_gold  comment_karma  link_karma  awarder_karma  \\\n55          \\n  NaN     NaN            NaN         NaN            NaN   \n312         \\n  NaN     NaN            NaN         NaN            NaN   \n768         \\n  NaN     NaN            NaN         NaN            NaN   \n1704        \\n  NaN     NaN            NaN         NaN            NaN   \n2528        \\n  NaN     NaN            NaN         NaN            NaN   \n\n      awardee_karma  total_karma created_utc update_dt  \n55              NaN          NaN         NaT       NaT  \n312             NaN          NaN         NaT       NaT  \n768             NaN          NaN         NaT       NaT  \n1704            NaN          NaN         NaT       NaT  \n2528            NaN          NaN         NaT       NaT  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>name</th>\n      <th>is_gold</th>\n      <th>comment_karma</th>\n      <th>link_karma</th>\n      <th>awarder_karma</th>\n      <th>awardee_karma</th>\n      <th>total_karma</th>\n      <th>created_utc</th>\n      <th>update_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55</th>\n      <td>\\n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>312</th>\n      <td>\\n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>\\n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>1704</th>\n      <td>\\n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>2528</th>\n      <td>\\n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_data.sort_values(by = ['author_id', 'update_dt'], inplace = True)\n",
    "author_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for duplicates\n",
    "do not dedup authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment_data (20306, 7) dedup: (20234, 7)\n"
     ]
    }
   ],
   "source": [
    "new_comment_data = comment_data.drop_duplicates(subset = ['submission_id', 'comment_id'])\n",
    "print('comment_data', comment_data.shape, 'dedup:', new_comment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_data (2755, 7) dedup: (2683, 7)\n"
     ]
    }
   ],
   "source": [
    "new_submission_data = submission_data.drop_duplicates(subset = ['submission_id', 'author_id'])\n",
    "print('submission_data', submission_data.shape, 'dedup:', new_submission_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_data (25597, 4) dedup: (25597, 4)\n"
     ]
    }
   ],
   "source": [
    "new_text_data = text_data.drop_duplicates(subset = ['id', 'type'])\n",
    "print('text_data', text_data.shape, 'dedup:', new_text_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_data (22988, 10) dedup: (19683, 10)\n"
     ]
    }
   ],
   "source": [
    "new_author_data = author_data.drop_duplicates(subset = ['author_id', 'update_dt'])\n",
    "print('author_data', author_data.shape, 'dedup:', new_author_data.shape)\n",
    "author_data = new_author_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [author_id, name, is_gold, comment_karma, link_karma, awarder_karma, awardee_karma, total_karma, created_utc, update_dt]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>name</th>\n      <th>is_gold</th>\n      <th>comment_karma</th>\n      <th>link_karma</th>\n      <th>awarder_karma</th>\n      <th>awardee_karma</th>\n      <th>total_karma</th>\n      <th>created_utc</th>\n      <th>update_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_data[author_data['author_id']=='zy579']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              id        type  \\\n0       \\nqo4gnp       title   \n1       \\nqo4gnp  submission   \n2      \\nhjkjs0s     comment   \n3      \\nhjkk07b     comment   \n4      \\nhjkk22t     comment   \n...          ...         ...   \n25664  \\nhmy7yz1     comment   \n25665  \\nhmycyjz     comment   \n25666  \\nhmy8hoa     comment   \n25667  \\nhmy9hex     comment   \n25668  \\nhmy7hkk     comment   \n\n                                                    text  negative  neutral  \\\n0             Is 3x leverage Alphabet too retarded? GOO3     0.381    0.619   \n1      Everyone knows Google is a monopoly and the st...     0.184    0.747   \n2       **User Report**| | | | :--|:--|:--|:-- **Tota...     0.082    0.918   \n3                               You belong here, retard.     0.531    0.469   \n4                    Why not just use the 3x index ETFs?     0.000    1.000   \n...                                                  ...       ...      ...   \n25664   Put it in stocks but forget about the ring part.     0.207    0.793   \n25665        Get a ring from a pawn shop and save money.     0.000    0.686   \n25666  Don't put it in stocks unless you want to take...     0.080    0.871   \n25667  Six months is *very* short term, you'd be taki...     0.038    0.962   \n25668  No. You’ll just have short term cap gains give...     0.126    0.571   \n\n       positive  compound  \n0         0.000   -0.5719  \n1         0.069   -0.8718  \n2         0.000   -0.3612  \n3         0.000   -0.5267  \n4         0.000    0.0000  \n...         ...       ...  \n25664     0.000   -0.3291  \n25665     0.314    0.4939  \n25666     0.049   -0.2023  \n25667     0.000   -0.2732  \n25668     0.303    0.4767  \n\n[25597 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>text</th>\n      <th>negative</th>\n      <th>neutral</th>\n      <th>positive</th>\n      <th>compound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nqo4gnp</td>\n      <td>title</td>\n      <td>Is 3x leverage Alphabet too retarded? GOO3</td>\n      <td>0.381</td>\n      <td>0.619</td>\n      <td>0.000</td>\n      <td>-0.5719</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nqo4gnp</td>\n      <td>submission</td>\n      <td>Everyone knows Google is a monopoly and the st...</td>\n      <td>0.184</td>\n      <td>0.747</td>\n      <td>0.069</td>\n      <td>-0.8718</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\nhjkjs0s</td>\n      <td>comment</td>\n      <td>**User Report**| | | | :--|:--|:--|:-- **Tota...</td>\n      <td>0.082</td>\n      <td>0.918</td>\n      <td>0.000</td>\n      <td>-0.3612</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nhjkk07b</td>\n      <td>comment</td>\n      <td>You belong here, retard.</td>\n      <td>0.531</td>\n      <td>0.469</td>\n      <td>0.000</td>\n      <td>-0.5267</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\nhjkk22t</td>\n      <td>comment</td>\n      <td>Why not just use the 3x index ETFs?</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25664</th>\n      <td>\\nhmy7yz1</td>\n      <td>comment</td>\n      <td>Put it in stocks but forget about the ring part.</td>\n      <td>0.207</td>\n      <td>0.793</td>\n      <td>0.000</td>\n      <td>-0.3291</td>\n    </tr>\n    <tr>\n      <th>25665</th>\n      <td>\\nhmycyjz</td>\n      <td>comment</td>\n      <td>Get a ring from a pawn shop and save money.</td>\n      <td>0.000</td>\n      <td>0.686</td>\n      <td>0.314</td>\n      <td>0.4939</td>\n    </tr>\n    <tr>\n      <th>25666</th>\n      <td>\\nhmy8hoa</td>\n      <td>comment</td>\n      <td>Don't put it in stocks unless you want to take...</td>\n      <td>0.080</td>\n      <td>0.871</td>\n      <td>0.049</td>\n      <td>-0.2023</td>\n    </tr>\n    <tr>\n      <th>25667</th>\n      <td>\\nhmy9hex</td>\n      <td>comment</td>\n      <td>Six months is *very* short term, you'd be taki...</td>\n      <td>0.038</td>\n      <td>0.962</td>\n      <td>0.000</td>\n      <td>-0.2732</td>\n    </tr>\n    <tr>\n      <th>25668</th>\n      <td>\\nhmy7hkk</td>\n      <td>comment</td>\n      <td>No. You’ll just have short term cap gains give...</td>\n      <td>0.126</td>\n      <td>0.571</td>\n      <td>0.303</td>\n      <td>0.4767</td>\n    </tr>\n  </tbody>\n</table>\n<p>25597 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis_util.sentiment import VaderSentiment\n",
    "\n",
    "vader = VaderSentiment()\n",
    "sentiment_data = vader.get_sentiment(show_text=True, dataframe= text_data)\n",
    "sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Data')"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUtElEQVR4nO3de5R1dX3f8feHixgqUS5TQkR8HrIQak0ROrWu2BUVxIAS0MQkjw0WFddTjTGY6rJY25jVpiuYNloT09pnIYFWCyYYGhrrBbnUNgXM81CQW7gJGhBlDPEWBbl8+8feAyfDXM7MnL3PzLPfr7VmzTl777N/3/mdM5+zz+/s8zupKiRJw7HHtAuQJPXL4JekgTH4JWlgDH5JGhiDX5IGZq9pFzCOgw46qLZs2TLtMiRpU9m1a9c3qmpm4fJNEfxbtmxh586d0y5DkjaVJF9ebLlDPZI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwm+KTu9JGsuWsTz5++e6zXznFSqS18Yhfkgams+BPcm6S+5PcuMi6dySpJAd11b4kaXFdHvGfB5y4cGGSZwEvB77SYduSpCV0FvxV9XnggUVWfQB4F+C3vEvSFPQ6xp/kVODeqrp+jG23J9mZZOfc3FwP1UnSMPQW/En2Bf4F8GvjbF9VO6pqtqpmZ2ae9D0CkqQ16vOI/8eArcD1Se4GDgWuTfIjPdYgSYPX23n8VXUD8Lfnr7fhP1tV3+irBklSt6dzXgBcBRyZ5J4kZ3TVliRpfJ0d8VfVa1dYv6WrtiVJS/OTu5I0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwHQW/EnOTXJ/khtHlv27JH+e5ItJLk7yjK7alyQtrssj/vOAExcsuxR4XlX9PeA24N0dti9JWkRnwV9VnwceWLDss1X1SHv1auDQrtqXJC1ummP8bwQ+tdTKJNuT7Eyyc25urseyJGn3NpXgT/Ie4BHgY0ttU1U7qmq2qmZnZmb6K06SdnN79d1gktcDJwPHV1X13b4kDV2vwZ/kROBdwIur6nt9ti1JanR5OucFwFXAkUnuSXIG8CFgP+DSJNcl+XBX7UuSFtfZEX9VvXaRxR/pqj1J0nj85K4kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDCdBX+Sc5Pcn+TGkWUHJLk0ye3t7/27al+StLguj/jPA05csOws4LKqOgK4rL0uSepRZ8FfVZ8HHliw+FTg/Pby+cCrumpfkrS4vsf4D66q+9rLXwMOXmrDJNuT7Eyyc25urp/qJGkApvbmblUVUMus31FVs1U1OzMz02NlkrR76zv4v57kEID29/09ty9Jg9d38F8CnN5ePh34457bl6TB6/J0zguAq4Ajk9yT5AzgbOCEJLcDL2uvS5J6tFdXO66q1y6x6viu2pQkrcxP7krSwBj8kjQwBr8kDYzBL0kDY/BL0sCMFfxJfjqJTxKStBsYN8x/Abg9yW8lOarLgiRJ3Ror+KvqNOAY4E7gvCRXtZOo7ddpdZKkiRt7+Kaqvg1cBFwIHAK8Grg2yds6qk2S1IFxx/hPTXIxcCWwN/CCqjoJOBp4R3flSZImbdwpG34G+ED75SqPq6rvtXPwSJI2iXGHer62MPSTvA+gqi6beFWSpM6MG/wnLLLspEkWIknqx7JDPUneAvwS8GNJvjiyaj/gT7ssTJLUjZXG+P8b8CngN4GzRpZ/p6oWfpG6JGkTWCn4q6ruTvLWhSuSHGD4S9LmM84R/8nALpovRs/IugIO76guSVJHlg3+qjq5/b21n3IkSV1b6c3dY5dbX1XXTrYcSVLXVhrq+e1l1hVw3FoaTfKrwJvafdwAvKGqHlzLviRJq7PSUM9LJ91gkmcCvwI8t6q+n+QPgG3AeZNuS5L0ZCsN9RxXVZcn+ZnF1lfVH62j3R9K8jCwL/DVNe5HkrRKKw31vBi4HPjpRdYVsOrgr6p7k/x74CvA94HPVtVnV7sfSdLarDTU89729xsm1WCS/YFTga3AN4E/THJaVX10wXbbge0Ahx122KSal6TBG3da5gOT/E6Sa5PsSvLBJAeusc2XAXdV1VxVPUzzquEnFm5UVTuqaraqZmdmZtbYlCRpoXEnabsQmAN+FnhNe/nja2zzK8ALk+ybJMDxwC1r3JckaZXGDf5DqurfVNVd7c9vAAevpcGquobmm7yupTmVcw9gx1r2JUlavXGD/7NJtiXZo/35eeAza220qt5bVUdV1fOq6nVV9dBa9yVJWp2VTuf8Dk/M0fN2YP4N2D2A7wLv7LI4SdLkrXRWz359FSJJ6se437k7fxrmEcBT55ct/DpGSdLGN1bwJ3kTcCZwKHAd8ELgKtY4V48kaXrGfXP3TOAfAF9u5+85hubDV5KkTWbc4H9wfvbMJPtU1Z8DR3ZXliSpK+OO8d+T5BnAfwcuTfJXwJe7KkqS1J2xgr+qXt1e/PUkVwBPBz7dWVWSpM6s5qyeY4F/RHNe/59W1Q86q0qS1JlxJ2n7NeB84EDgIOD3k/zLLguTJHVj3CP+XwSOHnmD92ya0zp/o6O6JEkdGfesnq8y8sEtYB/g3smXI0nq2kpz9fwuzZj+t4CbklzaXj8B+EL35UmSJm2loZ6d7e9dwMUjy6/spBpJUudWmqTt/PnLSZ4CPKe9emv77VmSpE1m3Ll6XkJzVs/dNFM0PyvJ6U7SJkmbz7hn9fw28PKquhUgyXOAC4C/31VhkqRujHtWz97zoQ9QVbcBe3dTkiSpS+Me8e9Kcg5PfAPXL/LEG7+SpE1k3OB/M/BW4Ffa6/8b+I+dVCRJ6tSKwZ9kT+D6qjoKeP8kGm1n+jwHeB7N5wLeWFVXTWLfkqTlrTjGX1WPArcmOWyC7X4Q+HT7ZHI0cMsE9y1JWsa4Qz3703xy9wvAX88vrKpTVttgkqcDPwm8vt3HDwBn+pSknowb/P9qgm1uBeZoZvg8muZTwWdW1V+PbpRkO7Ad4LDDJvliQ5KGbdmhniRPTfJ24OeAo2jm4f9f8z9rbHMv4FjgP1XVMTSvIM5auFFV7aiq2aqanZmZWWNTkqSFVhrjPx+YBW4ATqL5INd63QPcU1XXtNcvonkikCT1YKWhnudW1Y8DJPkIE5iRs6q+luQvkhzZfijseODm9e5XkjSelYL/8YnYquqRJJNq923Ax9qJ374EvGFSO5YkLW+l4D86ybfbywF+qL0eoKrqh9fSaFVdRzOEJEnq2UrTMu/ZVyGSpH6MO0mbJGk3YfBL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDBTC/4keyb5f0n+ZFo1SNIQTfOI/0zglim2L0mDNJXgT3Io8ErgnGm0L0lDNq0j/v8AvAt4bKkNkmxPsjPJzrm5ud4Kk6TdXe/Bn+Rk4P6q2rXcdlW1o6pmq2p2Zmamp+okafc3jSP+FwGnJLkbuBA4LslHp1CHJA1S78FfVe+uqkOraguwDbi8qk7ruw5JGirP45ekgdlrmo1X1ZXAldOsQZKGxiN+SRoYg1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgTH4JWlgDH5JGhiDX5IGxuCXpIEx+CVpYAx+SRoYg1+SBsbgl6SBMfglaWAMfkkaGINfkgbG4JekgTH4JWlgeg/+JM9KckWSm5PclOTMvmuQpCHbawptPgK8o6quTbIfsCvJpVV18xRqkaTB6f2Iv6ruq6pr28vfAW4Bntl3HZI0VFMd40+yBTgGuGaRdduT7Eyyc25urvfaJGl3NY2hHgCSPA34BPD2qvr2wvVVtQPYATA7O1s9l6cJ2HLWJx+/fPfZr5xiJZJGTeWIP8neNKH/sar6o2nUIElDNY2zegJ8BLilqt7fd/uSNHTTOOJ/EfA64Lgk17U/r5hCHZI0SL2P8VfV/wHSd7uSpIaf3JWkgTH4JWlgDH5JGhiDX5IGZmof4JK0e/EDe5uHR/ySNDAGvyQNjMEvSQNj8EvSwPjmrjYt30yU1sbgl7Qon1inY7TfoZu+N/gHxH9kSWDwS1olDyA2P4Nf0qbkE9DaGfzSQHQRlAvHozW+aT5xGfzaMDyC02Im9bhYz366fmz2/QRq8GtdDOvNaamg6fo+XO7xspGDeZx2R43WsBFfFRn8GktX/1gb8Z9id7IR+neaNYzTdhf1bYR+X47BvwlstKOZtWy/2r9hqe03+j/UYro6L7vPvpjkY2Gcbdbzt3Ud9pvxMbiQwb+BdPHPtVTIbKYH/qT6ZaknkC6CeNx9TqvWzWp3CN2NYCrBn+RE4IPAnsA5VXX2NOpYq3GP4DbCS0j/UZ7Q58v+9e7H+01d6j34k+wJ/B5wAnAP8GdJLqmqm/uuZZ7/pP3aCE+Im1XXf+dQ+nHopnHE/wLgjqr6EkCSC4FTgU6C3weyVtL3sJePSU3bNIL/mcBfjFy/B/iHCzdKsh3Y3l79bpJb19jeQcA31njbLlnX6ljX6ljX6mzUusj71lXbsxdbuGHf3K2qHcCO9e4nyc6qmp1ASRNlXatjXatjXauzUeuCbmqbxhex3As8a+T6oe0ySVIPphH8fwYckWRrkqcA24BLplCHJA1S70M9VfVIkl8GPkNzOue5VXVTh02ue7ioI9a1Ota1Ota1Ohu1LuigtlTVpPcpSdrA/LJ1SRoYg1+SBma3CP4kP5fkpiSPJVnytKckJya5NckdSc4aWb41yTXt8o+3bzpPoq4Dklya5Pb29/6LbPPSJNeN/DyY5FXtuvOS3DWy7vl91dVu9+hI25eMLJ9mfz0/yVXt/f3FJL8wsm6i/bXU42Vk/T7t339H2x9bRta9u11+a5KfWk8da6jrnyW5ue2fy5I8e2TdovdpT3W9PsncSPtvGll3enu/357k9J7r+sBITbcl+ebIui7769wk9ye5cYn1SfI7bd1fTHLsyLr19VdVbfof4O8ARwJXArNLbLMncCdwOPAU4Hrgue26PwC2tZc/DLxlQnX9FnBWe/ks4H0rbH8A8ACwb3v9POA1HfTXWHUB311i+dT6C3gOcER7+UeB+4BnTLq/lnu8jGzzS8CH28vbgI+3l5/bbr8PsLXdz5491vXSkcfQW+brWu4+7amu1wMfWuS2BwBfan/v317ev6+6Fmz/NpoTTjrtr3bfPwkcC9y4xPpXAJ8CArwQuGZS/bVbHPFX1S1VtdInex+fKqKqfgBcCJyaJMBxwEXtducDr5pQaae2+xt3v68BPlVV35tQ+0tZbV2Pm3Z/VdVtVXV7e/mrwP3AzITaH7Xo42WZei8Cjm/751Tgwqp6qKruAu5o99dLXVV1xchj6Gqaz8p0bZz+WspPAZdW1QNV9VfApcCJU6rrtcAFE2p7WVX1eZoDvaWcCvyXalwNPCPJIUygv3aL4B/TYlNFPBM4EPhmVT2yYPkkHFxV97WXvwYcvML223jyg+7fti/zPpBkn57remqSnUmunh9+YgP1V5IX0BzF3TmyeFL9tdTjZdFt2v74Fk3/jHPbLusadQbNUeO8xe7TPuv62fb+uSjJ/Ac5N0R/tUNiW4HLRxZ31V/jWKr2dffXhp2yYaEknwN+ZJFV76mqP+67nnnL1TV6paoqyZLnzrbP5D9O8/mGee+mCcCn0JzL+8+Bf91jXc+uqnuTHA5cnuQGmnBbswn3138FTq+qx9rFa+6v3VGS04BZ4MUji590n1bVnYvvYeL+B3BBVT2U5J/SvFo6rqe2x7ENuKiqHh1ZNs3+6symCf6qetk6d7HUVBF/SfMSaq/2qG1VU0gsV1eSryc5pKrua4Pq/mV29fPAxVX18Mi+549+H0ry+8A7+6yrqu5tf38pyZXAMcAnmHJ/Jflh4JM0T/pXj+x7zf21iHGmFpnf5p4kewFPp3k8dTktyVj7TvIymifTF1fVQ/PLl7hPJxFkK9ZVVX85cvUcmvd05m/7kgW3vXICNY1V14htwFtHF3TYX+NYqvZ199eQhnoWnSqimndLrqAZXwc4HZjUK4hL2v2Ns98njS224Tc/rv4qYNF3/7uoK8n+80MlSQ4CXgTcPO3+au+7i2nGPi9asG6S/TXO1CKj9b4GuLztn0uAbWnO+tkKHAF8YR21rKquJMcA/xk4paruH1m+6H3aY12HjFw9BbilvfwZ4OVtffsDL+dvvvLttK62tqNo3ii9amRZl/01jkuAf9Ke3fNC4Fvtwc36+6urd6z7/AFeTTPO9RDwdeAz7fIfBf7nyHavAG6jecZ+z8jyw2n+Me8A/hDYZ0J1HQhcBtwOfA44oF0+S/PNY/PbbaF5Ft9jwe0vB26gCbCPAk/rqy7gJ9q2r29/n7ER+gs4DXgYuG7k5/ld9NdijxeaoaNT2stPbf/+O9r+OHzktu9pb3crcNKEH+8r1fW59v9gvn8uWek+7amu3wRuatu/Ajhq5LZvbPvxDuANfdbVXv914OwFt+u6vy6gOSvtYZr8OgN4M/Dmdn1ovrTqzrb92ZHbrqu/nLJBkgZmSEM9kiQMfkkaHINfkgbG4JekgTH4JWlgDH5pgTwxI+NNSa5P8o4ky/6vJNmS5B/3VaO0Hga/9GTfr6rnV9XfBU4ATgLeu8JttgAGvzYFz+OXFkjy3ap62sj1w2k+AXoQ8GyaOYL+Vrv6l6vq/ya5mmZ68Lto5qC5eLHtevoTpGUZ/NICC4O/XfZNmu98+A7wWFU9mOQImknHZpO8BHhnVZ3cbr/vYtv1+XdIS9k0k7RJG8TewIfSfLvXozRfDLOe7aTeGfzSCtqhnkdpZgt9L808OEfTvEf24BI3+9Uxt5N655u70jKSzNB8veSHqhkXfTpwXzXfAfA6mq/2g2YIaL+Rmy61nTR1jvFLCyR5lGY2xL2BR2jepH1/VT3Wjtd/Aijg08Bbq+ppSfammRr3QJrv/v2Txbbr+2+RFmPwS9LAONQjSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MP8fIqvh1mv11tUAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "x = sentiment_data['compound']\n",
    "\n",
    "plt.hist(x, density=True, bins=100)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = sentiment_data[sentiment_data['type'].isin(['submission', 'comment'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data.loc[(sentiment_data['compound']>-0.3)&(sentiment_data['compound']<0.3), 'sentiment'] = 'neutral'\n",
    "\n",
    "sentiment_data.loc[(sentiment_data['compound']>=0.3), 'sentiment'] = 'positive'\n",
    "\n",
    "sentiment_data.loc[(sentiment_data['compound']<=-0.3), 'sentiment'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "neutral     9745\npositive    8204\nnegative    4966\nName: sentiment, dtype: int64"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Validation using AWS Comprehend Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_util.sentiment import AwsComprehendSentiment\n",
    "\n",
    "comprehend = AwsComprehendSentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception 'body'\n",
      "Exception 'body'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\NLISIC~1\\AppData\\Local\\Temp/ipykernel_11792/3704814993.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# WARNING: TAKES A LONG TIME TO EXECUTE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0msentiment_data_validation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcomprehend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_sentiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mtext_data\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0msentiment_data_validation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Georgia Tech\\6242-finance-project\\analysis_util\\sentiment.py\u001B[0m in \u001B[0;36mget_sentiment\u001B[1;34m(self, filename, dataframe, show_text)\u001B[0m\n\u001B[0;32m     72\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Exception {str(ex)}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m         \u001B[0mdf_sentiment_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_text_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentiment\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mdf_sentiment_data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   8738\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8739\u001B[0m         )\n\u001B[1;32m-> 8740\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   8741\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8742\u001B[0m     def applymap(\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    686\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    689\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    690\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    811\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 812\u001B[1;33m         \u001B[0mresults\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    813\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    814\u001B[0m         \u001B[1;31m# wrap results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    826\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m                 \u001B[1;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m                 \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m                     \u001B[1;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Georgia Tech\\6242-finance-project\\analysis_util\\sentiment.py\u001B[0m in \u001B[0;36msentiment\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     53\u001B[0m             \u001B[0mpayload\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'body'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 55\u001B[1;33m                 resp = requests.post(self.url,\n\u001B[0m\u001B[0;32m     56\u001B[0m                                      payload)\n\u001B[0;32m     57\u001B[0m                 \u001B[0mss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'body'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'SentimentScore'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mpost\u001B[1;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m     \"\"\"\n\u001B[0;32m    116\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'post'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\api.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;31m# cases, and look like a memory leak in others.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0msessions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    540\u001B[0m         }\n\u001B[0;32m    541\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m         \u001B[0mresp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\sessions.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    653\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    654\u001B[0m         \u001B[1;31m# Send the request\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 655\u001B[1;33m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    656\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    657\u001B[0m         \u001B[1;31m# Total elapsed time of the request (approximately)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\adapters.py\u001B[0m in \u001B[0;36msend\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    437\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mchunked\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 439\u001B[1;33m                 resp = conn.urlopen(\n\u001B[0m\u001B[0;32m    440\u001B[0m                     \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    441\u001B[0m                     \u001B[0murl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    697\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    698\u001B[0m             \u001B[1;31m# Make the request on the httplib connection object.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 699\u001B[1;33m             httplib_response = self._make_request(\n\u001B[0m\u001B[0;32m    700\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    380\u001B[0m         \u001B[1;31m# Trigger any extra validation we need to do.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_conn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m             \u001B[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001B[0m in \u001B[0;36m_validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1008\u001B[0m         \u001B[1;31m# Force connect early to allow us to validate the connection.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1009\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"sock\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# AppEngine might not have  `.sock`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1010\u001B[1;33m             \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1011\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1012\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mconn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_verified\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\connection.py\u001B[0m in \u001B[0;36mconnect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    414\u001B[0m             \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_default_certs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    415\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 416\u001B[1;33m         self.sock = ssl_wrap_socket(\n\u001B[0m\u001B[0;32m    417\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m             \u001B[0mkeyfile\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkey_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36mssl_wrap_socket\u001B[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[0;32m    447\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msend_sni\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 449\u001B[1;33m         ssl_sock = _ssl_wrap_socket_impl(\n\u001B[0m\u001B[0;32m    450\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtls_in_tls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    451\u001B[0m         )\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001B[0m in \u001B[0;36m_ssl_wrap_socket_impl\u001B[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    492\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 493\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mserver_hostname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_hostname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    494\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    495\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mssl_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrap_socket\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\u001B[0m in \u001B[0;36mwrap_socket\u001B[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;31m# SSLSocket class handles server_hostname encoding before it calls\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    499\u001B[0m         \u001B[1;31m# ctx._wrap_socket()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 500\u001B[1;33m         return self.sslsocket_class._create(\n\u001B[0m\u001B[0;32m    501\u001B[0m             \u001B[0msock\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msock\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m             \u001B[0mserver_side\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mserver_side\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\u001B[0m in \u001B[0;36m_create\u001B[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[0;32m   1038\u001B[0m                         \u001B[1;31m# non-blocking\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1039\u001B[0m                         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mOSError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nlisichenok\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\u001B[0m in \u001B[0;36mdo_handshake\u001B[1;34m(self, block)\u001B[0m\n\u001B[0;32m   1307\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0.0\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1308\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1309\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_handshake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1310\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1311\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msettimeout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# WARNING: TAKES A LONG TIME TO EXECUTE\n",
    "#\n",
    "sentiment_data_validation = comprehend.get_sentiment(dataframe= text_data) #\n",
    "\n",
    "sentiment_data_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_data_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\NLISIC~1\\AppData\\Local\\Temp/ipykernel_11792/898216627.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m42\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msentiment_data_validation\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'compound'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdensity\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# density=False would make counts\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mylabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Probability'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'sentiment_data_validation' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = sentiment_data_validation['compound']\n",
    "\n",
    "plt.hist(x, density=True, bins=100)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data.loc[(sentiment_data['neutral']>sentiment_data['negative']) & \n",
    "                   (sentiment_data['neutral']>sentiment_data['positive']), 'sentiment'] = 'neutral'\n",
    "sentiment_data.loc[(sentiment_data['positive']>sentiment_data['negative']) & \n",
    "                   (sentiment_data['positive']>sentiment_data['neutral']), 'sentiment'] = 'positive'\n",
    "sentiment_data.loc[(sentiment_data['negative']>sentiment_data['neutral']) & \n",
    "                   (sentiment_data['negative']>sentiment_data['positive']), 'sentiment'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "neutral     9745\npositive    8204\nnegative    4966\nName: sentiment, dtype: int64"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data_validation.loc[\n",
    "    (sentiment_data_validation['neutral']>sentiment_data_validation['negative']) & \n",
    "    (sentiment_data_validation['neutral']>sentiment_data_validation['positive']), 'sentiment_comprehend'] = 'neutral'\n",
    "\n",
    "sentiment_data_validation.loc[\n",
    "    (sentiment_data_validation['positive']>sentiment_data_validation['negative']) & \n",
    "    (sentiment_data_validation['positive']>sentiment_data_validation['neutral']), 'sentiment_comprehend'] = 'positive'\n",
    "\n",
    "sentiment_data_validation.loc[\n",
    "    (sentiment_data_validation['negative']>sentiment_data_validation['positive']) & \n",
    "    (sentiment_data_validation['negative']>sentiment_data_validation['neutral']), 'sentiment_comprehend'] = 'negative'\n",
    "\n",
    "sentiment_data_validation['sentiment_comprehend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sentiment_data.merge(sentiment_data_validation, on=['id', 'type'])\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x['sentiment'] != x['sentiment_comprehend']][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_non_matching = len(x[x['sentiment'] != x['sentiment_comprehend']])/len(x)\n",
    "percent_non_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TickersMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          id        type tickers\n0   \\nqo4gnp       title        \n1   \\nqo4gnp  submission    GOOG\n2  \\nhjkjs0s     comment        \n3  \\nhjkk07b     comment        \n4  \\nhjkk22t     comment        ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>tickers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nqo4gnp</td>\n      <td>title</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nqo4gnp</td>\n      <td>submission</td>\n      <td>GOOG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\nhjkjs0s</td>\n      <td>comment</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nhjkk07b</td>\n      <td>comment</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\nhjkk22t</td>\n      <td>comment</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mining import TickersMining\n",
    "\n",
    "miner = TickersMining(stock_data='input/stock_data.csv')\n",
    "\n",
    "ticker_data = miner.get_tickers(dataframe=text_data)\n",
    "\n",
    "ticker_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_data = ticker_data[(ticker_data['tickers'].notnull()) & (ticker_data['tickers']!=\"\")]\n",
    "ticker_data['tickers_list'] = ticker_data['tickers'].str.split('|')\n",
    "ticker_data = ticker_data.explode('tickers_list').reset_index(drop=True)\n",
    "\n",
    "ticker_data.rename(columns={\"tickers_list\": \"ticker\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ticker_data_notnull (10006, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          id        type tickers ticker\n0   \\nqo4gnp  submission    GOOG   GOOG\n1   \\nqo3u6q  submission  IRS|RH    IRS\n2   \\nqo3u6q  submission  IRS|RH     RH\n3  \\nhjkft58     comment      GO     GO\n4   \\nqo6px6  submission  MLI|PB    MLI",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>tickers</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nqo4gnp</td>\n      <td>submission</td>\n      <td>GOOG</td>\n      <td>GOOG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nqo3u6q</td>\n      <td>submission</td>\n      <td>IRS|RH</td>\n      <td>IRS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\nqo3u6q</td>\n      <td>submission</td>\n      <td>IRS|RH</td>\n      <td>RH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nhjkft58</td>\n      <td>comment</td>\n      <td>GO</td>\n      <td>GO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\nqo6px6</td>\n      <td>submission</td>\n      <td>MLI|PB</td>\n      <td>MLI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('df_ticker_data_notnull', ticker_data.shape)\n",
    "ticker_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique tickers: 1182\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_tickers = list(np.unique(ticker_data.ticker))\n",
    "\n",
    "print('number of unique tickers:', len(unique_tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission data: Concat Submission and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_1 = submission_data.copy()\n",
    "df_submission_1 = df_submission_1[['submission_id', 'author_id', 'score', 'created_utc', 'update_dt']]\n",
    "\n",
    "df_submission_1.rename(columns={'submission_id': 'id'}, inplace = True)\n",
    "\n",
    "df_submission_1['type'] = 'submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_2 = comment_data.copy()\n",
    "df_submission_2 = df_submission_2[['comment_id', 'author_id', 'score', 'created_utc', 'update_dt']]\n",
    "\n",
    "df_submission_2.rename(columns={'comment_id': 'id'}, inplace = True)\n",
    "\n",
    "df_submission_2['type'] = 'comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_comment_data = pd.concat([df_submission_1, df_submission_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in: Join Sentiment , submission/comment, ticker data and author data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "sentiment_data.replace('\\n','', regex=True, inplace=True)\n",
    "ticker_data.replace('\\n','', regex=True, inplace=True)\n",
    "author_data.replace('\\n','', regex=True, inplace=True)\n",
    "submission_comment_data.replace('\\n','', regex=True, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "neutral     9745\npositive    8204\nnegative    4966\nName: sentiment, dtype: int64"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "        id        type                                               text  \\\n0   qo4gnp  submission  Everyone knows Google is a monopoly and the st...   \n1  hjkjs0s     comment   **User Report**| | | | :--|:--|:--|:-- **Tota...   \n2  hjkk07b     comment                           You belong here, retard.   \n3  hjkk22t     comment                Why not just use the 3x index ETFs?   \n4  hjklona     comment    Why can’t you just buy fds like a normal person   \n\n   negative  neutral  positive  compound sentiment  \n0     0.184    0.747     0.069   -0.8718  negative  \n1     0.082    0.918     0.000   -0.3612  negative  \n2     0.531    0.469     0.000   -0.5267  negative  \n3     0.000    1.000     0.000    0.0000   neutral  \n4     0.000    0.762     0.238    0.3612  positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>text</th>\n      <th>negative</th>\n      <th>neutral</th>\n      <th>positive</th>\n      <th>compound</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>qo4gnp</td>\n      <td>submission</td>\n      <td>Everyone knows Google is a monopoly and the st...</td>\n      <td>0.184</td>\n      <td>0.747</td>\n      <td>0.069</td>\n      <td>-0.8718</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hjkjs0s</td>\n      <td>comment</td>\n      <td>**User Report**| | | | :--|:--|:--|:-- **Tota...</td>\n      <td>0.082</td>\n      <td>0.918</td>\n      <td>0.000</td>\n      <td>-0.3612</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hjkk07b</td>\n      <td>comment</td>\n      <td>You belong here, retard.</td>\n      <td>0.531</td>\n      <td>0.469</td>\n      <td>0.000</td>\n      <td>-0.5267</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hjkk22t</td>\n      <td>comment</td>\n      <td>Why not just use the 3x index ETFs?</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hjklona</td>\n      <td>comment</td>\n      <td>Why can’t you just buy fds like a normal person</td>\n      <td>0.000</td>\n      <td>0.762</td>\n      <td>0.238</td>\n      <td>0.3612</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "        id        type tickers ticker\n0   qo4gnp  submission    GOOG   GOOG\n1   qo3u6q  submission  IRS|RH    IRS\n2   qo3u6q  submission  IRS|RH     RH\n3  hjkft58     comment      GO     GO\n4   qo6px6  submission  MLI|PB    MLI",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>tickers</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>qo4gnp</td>\n      <td>submission</td>\n      <td>GOOG</td>\n      <td>GOOG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>qo3u6q</td>\n      <td>submission</td>\n      <td>IRS|RH</td>\n      <td>IRS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>qo3u6q</td>\n      <td>submission</td>\n      <td>IRS|RH</td>\n      <td>RH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hjkft58</td>\n      <td>comment</td>\n      <td>GO</td>\n      <td>GO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>qo6px6</td>\n      <td>submission</td>\n      <td>MLI|PB</td>\n      <td>MLI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "data": {
      "text/plain": "  author_id                 name  is_gold  comment_karma  link_karma  \\\n0    100cej          SQRTLURFACE     True        36042.0       227.0   \n1    1019wg           shawmahawk    False        10931.0      1476.0   \n2    101di1  Many-machines-on-ix    False          258.0       556.0   \n3    102k1d               JRMang     True       109510.0     18582.0   \n4    102k1d               JRMang     True       109760.0     18582.0   \n\n   awarder_karma  awardee_karma  total_karma         created_utc  \\\n0          761.0          181.0      37211.0 2016-08-01 06:54:28   \n1           44.0          661.0      13112.0 2016-08-01 21:46:32   \n2           77.0           68.0        959.0 2016-08-01 22:59:11   \n3         1008.0         3019.0     132119.0 2016-08-02 18:37:53   \n4         1027.0         3019.0     132388.0 2016-08-02 18:37:53   \n\n            update_dt  \n0 2021-11-10 03:00:00  \n1 2021-11-09 05:00:00  \n2 2021-11-27 14:00:00  \n3 2021-11-12 17:00:00  \n4 2021-11-18 05:00:00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_id</th>\n      <th>name</th>\n      <th>is_gold</th>\n      <th>comment_karma</th>\n      <th>link_karma</th>\n      <th>awarder_karma</th>\n      <th>awardee_karma</th>\n      <th>total_karma</th>\n      <th>created_utc</th>\n      <th>update_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100cej</td>\n      <td>SQRTLURFACE</td>\n      <td>True</td>\n      <td>36042.0</td>\n      <td>227.0</td>\n      <td>761.0</td>\n      <td>181.0</td>\n      <td>37211.0</td>\n      <td>2016-08-01 06:54:28</td>\n      <td>2021-11-10 03:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1019wg</td>\n      <td>shawmahawk</td>\n      <td>False</td>\n      <td>10931.0</td>\n      <td>1476.0</td>\n      <td>44.0</td>\n      <td>661.0</td>\n      <td>13112.0</td>\n      <td>2016-08-01 21:46:32</td>\n      <td>2021-11-09 05:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>101di1</td>\n      <td>Many-machines-on-ix</td>\n      <td>False</td>\n      <td>258.0</td>\n      <td>556.0</td>\n      <td>77.0</td>\n      <td>68.0</td>\n      <td>959.0</td>\n      <td>2016-08-01 22:59:11</td>\n      <td>2021-11-27 14:00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102k1d</td>\n      <td>JRMang</td>\n      <td>True</td>\n      <td>109510.0</td>\n      <td>18582.0</td>\n      <td>1008.0</td>\n      <td>3019.0</td>\n      <td>132119.0</td>\n      <td>2016-08-02 18:37:53</td>\n      <td>2021-11-12 17:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102k1d</td>\n      <td>JRMang</td>\n      <td>True</td>\n      <td>109760.0</td>\n      <td>18582.0</td>\n      <td>1027.0</td>\n      <td>3019.0</td>\n      <td>132388.0</td>\n      <td>2016-08-02 18:37:53</td>\n      <td>2021-11-18 05:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_data.dropna(inplace=True)\n",
    "author_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "       id author_id  score         created_utc           update_dt        type\n0  qo4gnp  845k3tg2    4.0 2021-11-06 17:01:17 2021-11-06 17:00:00  submission\n1  qo3u6q  8spa6hs8   38.0 2021-11-06 16:29:41 2021-11-06 17:00:00  submission\n2  qo6px6  3jrwyqto    3.0 2021-11-06 18:54:19 2021-11-06 19:00:00  submission\n3  qo6219  45ffug98   51.0 2021-11-06 18:20:41 2021-11-06 19:00:00  submission\n4  qo5mlh  9v2gh7xx   39.0 2021-11-06 17:59:50 2021-11-06 19:00:00  submission",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>author_id</th>\n      <th>score</th>\n      <th>created_utc</th>\n      <th>update_dt</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>qo4gnp</td>\n      <td>845k3tg2</td>\n      <td>4.0</td>\n      <td>2021-11-06 17:01:17</td>\n      <td>2021-11-06 17:00:00</td>\n      <td>submission</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>qo3u6q</td>\n      <td>8spa6hs8</td>\n      <td>38.0</td>\n      <td>2021-11-06 16:29:41</td>\n      <td>2021-11-06 17:00:00</td>\n      <td>submission</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>qo6px6</td>\n      <td>3jrwyqto</td>\n      <td>3.0</td>\n      <td>2021-11-06 18:54:19</td>\n      <td>2021-11-06 19:00:00</td>\n      <td>submission</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>qo6219</td>\n      <td>45ffug98</td>\n      <td>51.0</td>\n      <td>2021-11-06 18:20:41</td>\n      <td>2021-11-06 19:00:00</td>\n      <td>submission</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>qo5mlh</td>\n      <td>9v2gh7xx</td>\n      <td>39.0</td>\n      <td>2021-11-06 17:59:50</td>\n      <td>2021-11-06 19:00:00</td>\n      <td>submission</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_comment_data.dropna(inplace=True)\n",
    "submission_comment_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_data = sentiment_data.merge(ticker_data, on=['id', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\", line 1035, in _pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 144, in cmd_step_over\n",
      "    if _is_inside_jupyter_cell(frame, pydb):\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 209, in _is_inside_jupyter_cell\n",
      "    if is_cell_filename(filename):\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 220, in is_cell_filename\n",
      "    ipython_shell = get_ipython()\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "flatten_data = flatten_data.merge(submission_comment_data, on=['id', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_data = flatten_data.merge(author_data, on=['author_id', 'update_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "'id',\n",
    "'type',\n",
    "'negative', \n",
    "'neutral', \n",
    "'positive', \n",
    "'compound', \n",
    "'sentiment', \n",
    "'ticker', \n",
    "'author_id',\n",
    "'score',\n",
    "'created_utc_x',\n",
    "'update_dt',\n",
    "'comment_karma',\n",
    "'link_karma',\n",
    "'awarder_karma',\n",
    "'awardee_karma',\n",
    "'total_karma'\n",
    "]\n",
    "flatten_data = flatten_data[cols]\n",
    "\n",
    "flatten_data.rename(columns={'created_utc_x': 'created_utc'}, inplace = True)\n",
    "\n",
    "flatten_data.to_csv(path_or_buf=f'output/backup4/flatten_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo hourly price with Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments agg by hour\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "flatten_data = pd.read_csv(f'output/backup/flatten_data.csv', index_col=None, header=0)\n",
    "df_sentiment_temp = flatten_data.copy()\n",
    "df_sentiment_temp['created_utc'] = pd.to_datetime(df_sentiment_temp['created_utc'])\n",
    "df_sentiment_temp['Date'] = df_sentiment_temp['created_utc'].dt.ceil('h')\n",
    "sentiment_dummies = pd.get_dummies(df_sentiment_temp['sentiment'], prefix= 'sent')\n",
    "df_sentiment_temp = pd.concat([df_sentiment_temp, sentiment_dummies], axis=1)  \n",
    "\n",
    "df_sentiment_temp = df_sentiment_temp[['ticker', 'Date', 'sent_negative', 'sent_neutral', 'sent_positive']]\n",
    "df_sentiment_agg = df_sentiment_temp.groupby(['ticker', 'Date']).sum().reset_index()\n",
    "df_sentiment_agg.rename(columns={'ticker': 'Ticker'}, inplace = True)\n",
    "df_sentiment_agg['mentions'] = df_sentiment_agg.sent_negative + df_sentiment_agg.sent_neutral + df_sentiment_agg.sent_positive\n",
    "\n",
    "df_sentiment_agg['Date'] = df_sentiment_agg['Date'].dt.tz_localize('UTC')#.dt.tz_convert('America/New_York')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_agg['origin'] = pd.Timestamp(\"1970-01-01\", tz = 'UTC')\n",
    "df_sentiment_agg['timestamp'] = (df_sentiment_agg['Date'] - df_sentiment_agg['origin'] )\n",
    "df_sentiment_agg['timestamp'] = df_sentiment_agg['timestamp'].values.astype(int)\n",
    "\n",
    "del df_sentiment_agg['origin'] \n",
    "del df_sentiment_agg['Date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the mentionned tickers in reddit\n",
    "reddit_tickers = list(np.unique(df_sentiment_agg['Ticker']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  Ticker  sent_negative  sent_neutral  sent_positive  mentions   timestamp\n0     AA              0             1              0         1   349388800\n1     AA              0             1              0         1   277667840\n2     AA              0             1              0         1  -762019840\n3     AA              0             1              0         1  1231290368\n4    AAL              0             1              0         1  1726005248",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticker</th>\n      <th>sent_negative</th>\n      <th>sent_neutral</th>\n      <th>sent_positive</th>\n      <th>mentions</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>349388800</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>277667840</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-762019840</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1231290368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAL</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1726005248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.64\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "\n",
      "1 Failed download:\n",
      "- EMP: None\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  100 of 100 completed\n",
      "[*********************100%***********************]  98 of 98 completed\n"
     ]
    }
   ],
   "source": [
    "# retrieve all the hourly closing prices for each ticker\n",
    "import yfinance as yf\n",
    "print(yf.__version__)\n",
    "\n",
    "prices = []\n",
    "i=0\n",
    "while i< len(reddit_tickers):\n",
    "    start = i\n",
    "    end = i+100\n",
    "    if end>len(reddit_tickers):\n",
    "        end = len(reddit_tickers)\n",
    "    \n",
    "    data = yf.download( tickers = reddit_tickers[start:end], period = \"1mo\",interval = \"1h\",group_by = 'ticker', \n",
    "                       auto_adjust = True, prepost = True, threads = True, proxy = None)\n",
    "    \n",
    "#     data = yf.download(tickers=reddit_tickers[i], period=\"1mo\", interval=\"1h\",prepost = True)\n",
    "    data = data.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n",
    "    data.reset_index(inplace = True)\n",
    "#     print(data.shape)\n",
    "    prices.append(data)\n",
    "#     i = i+1\n",
    "    i = i+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = pd.concat(prices, ignore_index=True)\n",
    "price_data['Date'] = price_data['Date'].dt.tz_convert('UTC')\n",
    "\n",
    "price_data['origin'] = pd.Timestamp(\"1970-01-01\", tz = 'UTC')\n",
    "price_data['timestamp'] = (price_data['Date'] - price_data['origin'] )\n",
    "price_data['timestamp'] = price_data['timestamp'].values.astype(int)\n",
    "\n",
    "del price_data['origin'] \n",
    "\n",
    "price_data = price_data[['timestamp','Ticker', 'Close']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   timestamp Ticker       Close\n0  471314432     AA   47.669399\n1  471314432    AAL   20.455000\n2  471314432   AAON   71.620003\n3  471314432    AAP  229.500000\n4  471314432   AAPL  150.559998",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>Ticker</th>\n      <th>Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>471314432</td>\n      <td>AA</td>\n      <td>47.669399</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>471314432</td>\n      <td>AAL</td>\n      <td>20.455000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>471314432</td>\n      <td>AAON</td>\n      <td>71.620003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>471314432</td>\n      <td>AAP</td>\n      <td>229.500000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>471314432</td>\n      <td>AAPL</td>\n      <td>150.559998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All datetimes per tickers (after market hours and week ends)\n",
    "import datetime\n",
    "\n",
    "numhours = 30*24\n",
    "\n",
    "base = datetime.datetime.today()\n",
    "date_list = [base - datetime.timedelta(hours=x) for x in range(numhours)]\n",
    "df_date_time = pd.DataFrame({'Date': date_list})\n",
    "df_date_time['Date'] = df_date_time['Date'].dt.floor('h')\n",
    "df_date_time['Date'] = df_date_time['Date'].dt.tz_localize('UTC')#.dt.tz_convert('America/New_York')\n",
    "\n",
    "df_reddit_tickers  = pd.DataFrame({'Ticker': reddit_tickers})\n",
    "\n",
    "df_date_time['origin'] = pd.Timestamp(\"1970-01-01\", tz = 'UTC')\n",
    "df_date_time['timestamp'] = (df_date_time['Date'] - df_date_time['origin'] )\n",
    "df_date_time['timestamp'] = df_date_time['timestamp'].values.astype(int)\n",
    "\n",
    "del df_date_time['origin'] \n",
    "\n",
    "df_date_time['key'] = 0\n",
    "df_reddit_tickers['key'] = 0\n",
    "\n",
    "\n",
    "df_reddit_tickers_time = df_date_time.merge(df_reddit_tickers,  on='key', how='outer') #cross join\n",
    "df_reddit_tickers_time = df_reddit_tickers_time[['Date', 'timestamp', 'Ticker']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Date         datetime64[ns, UTC]\ntimestamp                  int32\nkey                        int64\ndtype: object"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date_time.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_data: fill up the missing hours(after hours and weekends/holiday)\n",
    "price_data_all = df_reddit_tickers_time.merge(price_data, on=['timestamp', 'Ticker'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  Ticker  sent_negative  sent_neutral  sent_positive  mentions   timestamp\n0     AA              0             1              0         1   349388800\n1     AA              0             1              0         1   277667840\n2     AA              0             1              0         1  -762019840\n3     AA              0             1              0         1  1231290368\n4    AAL              0             1              0         1  1726005248",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticker</th>\n      <th>sent_negative</th>\n      <th>sent_neutral</th>\n      <th>sent_positive</th>\n      <th>mentions</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>349388800</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>277667840</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-762019840</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1231290368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAL</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1726005248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sentiment data on the price data\n",
    "sentiment_price_data = price_data_all.merge(df_sentiment_agg, on=['timestamp', 'Ticker'], how = 'left')\n",
    "sentiment_price_data = sentiment_price_data[['Date', 'Ticker', 'Close', 'sent_negative', 'sent_neutral', 'sent_positive', 'mentions']].copy()\n",
    "\n",
    "sentiment_price_data[['sent_negative','sent_neutral','sent_positive','mentions']] = sentiment_price_data[['sent_negative','sent_neutral','sent_positive','mentions']].fillna(value=0)\n",
    "\n",
    "# df_sentiment_price.fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(790560, 7)"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_price_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Date             datetime64[ns, UTC]\nTicker                        object\nClose                        float64\nsent_negative                float64\nsent_neutral                 float64\nsent_positive                float64\nmentions                     float64\ndtype: object"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_price_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the imported data for Future re-use (backup)\n",
    "so you don't have to reload the data from S3 every time you restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = f'output/backup4'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_price_data.to_csv(path_or_buf=f'{outdir}/sentiment_price_data.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Date             datetime64[ns, UTC]\nTicker                        object\nClose                        float64\nsent_negative                float64\nsent_neutral                 float64\nsent_positive                float64\nmentions                     float64\ndtype: object"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_price_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# path_to_save = f'output/{bucket}/{f}/{bucket}_{f}_{yyyymmdd_hh_mm}.csv'\n",
    "# df.to_csv(path_or_buf=path_to_save, encoding='utf-8', index=False)\n",
    "\n",
    "author_data.to_csv(path_or_buf=f'{outdir}/author_data.csv', encoding='utf-8', index=False)\n",
    "comment_data.to_csv(path_or_buf=f'{outdir}/comment_data.csv', encoding='utf-8', index=False)\n",
    "submission_data.to_csv(path_or_buf=f'{outdir}/submission_data.csv', encoding='utf-8', index=False)\n",
    "text_data.to_csv(path_or_buf=f'{outdir}/text_data.csv', encoding='utf-8', index=False)\n",
    "sentiment_data.to_csv(path_or_buf=f'{outdir}/sentiment_data.csv', encoding='utf-8', index=False)\n",
    "ticker_data.to_csv(path_or_buf=f'{outdir}/ticker_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "submission_comment_data.to_csv(path_or_buf=f'{outdir}/submission_comment_data.csv', encoding='utf-8', index=False)\n",
    "flatten_data.to_csv(path_or_buf=f'{outdir}/flatten_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "sentiment_price_data.to_csv(path_or_buf=f'{outdir}/sentiment_price_data.csv', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data = pd.read_csv(f'{outdir}/author_data.csv', index_col=None, header=0)\n",
    "comment_data = pd.read_csv(f'{outdir}/comment_data.csv', index_col=None, header=0)\n",
    "submission_data = pd.read_csv(f'{outdir}/submission_data.csv', index_col=None, header=0)\n",
    "text_data = pd.read_csv(f'{outdir}/text_data.csv', index_col=None, header=0)\n",
    "sentiment_data = pd.read_csv(f'{outdir}/sentiment_data.csv', index_col=None, header=0)\n",
    "ticker_data = pd.read_csv(f'{outdir}/ticker_data.csv', index_col=None, header=0)\n",
    "submission_comment_data = pd.read_csv(f'{outdir}/submission_comment_data.csv', index_col=None, header=0)\n",
    "flatten_data = pd.read_csv(f'{outdir}/flatten_data.csv', index_col=None, header=0)\n",
    "\n",
    "\n",
    "\n",
    "author_data['created_utc'] = pd.to_datetime(author_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "author_data['update_dt'] = pd.to_datetime(author_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "comment_data['created_utc'] = pd.to_datetime(comment_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "comment_data['update_dt'] = pd.to_datetime(comment_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "submission_data['created_utc'] = pd.to_datetime(submission_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "submission_data['update_dt'] = pd.to_datetime(submission_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "text_data['update_dt'] = pd.to_datetime(text_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "submission_comment_data['created_utc'] = pd.to_datetime(submission_comment_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "submission_comment_data['update_dt'] = pd.to_datetime(submission_comment_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "flatten_data['created_utc'] = pd.to_datetime(flatten_data['created_utc'], format='%Y-%m-%d %H:%M:%S')\n",
    "flatten_data['update_dt'] = pd.to_datetime(flatten_data['update_dt'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "sentiment_price_data = pd.read_csv(f'{outdir}/sentiment_price_data.csv', index_col=None, header=0)\n",
    "sentiment_price_data['Date'] = pd.to_datetime(sentiment_price_data['Date'], format='%Y-%m-%d %H:%M:%S')\n",
    "sentiment_price_data['Date'] = sentiment_price_data['Date'].dt.tz_convert('America/New_York')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Date             datetime64[ns, America/New_York]\nTicker                                     object\nClose                                     float64\nsent_negative                             float64\nsent_neutral                              float64\nsent_positive                             float64\nmentions                                  float64\ndtype: object"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_price_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
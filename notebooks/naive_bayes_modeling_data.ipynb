{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from analysis_util.mining import TickersMining\n",
    "from analysis_util.sentiment import VaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add Functions for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def combine_subreddit_texts_by_date(subreddits=['investing', 'stocks', 'wallstreetbets'], date='20211111'):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for subreddit in subreddits:\n",
    "        dataframe = dataframe.append(\n",
    "            pd.read_csv('input_data/naive_bayes_input/' + subreddit + '/text_data/' + subreddit + '_text_data_' + date + '.csv'),\n",
    "            ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def add_bearish_or_bullish_class(df, stock_data):\n",
    "    merged = df.merge(stock_data, how='inner', left_on='tickers', right_on='symbol')\n",
    "    merged['class'] = merged['netchange'].apply(lambda x: 'bull' if x > 0 else 'bear')\n",
    "    return merged.drop(columns=['symbol', 'lastsale', 'netchange', 'volume', 'marketCap', 'ipoyear', 'industry',\n",
    "                                'sector', 'url', 'country', 'name', 'pctchange'])\n",
    "\n",
    "\n",
    "def clean_tickers(sentiment_data):\n",
    "    to_remove = [\"A\", \"DD\", \"SE\", \"TA\", \"SC\"]\n",
    "    single_tickers = pd.DataFrame(\n",
    "        columns=['id', 'type', 'text', 'negative', 'neutral', 'positive', 'compound', 'tickers'])\n",
    "\n",
    "    for a in range(0, len(sentiment_data.index)):\n",
    "        if isinstance(sentiment_data.iloc[a].loc[\"tickers\"], float):\n",
    "            pass\n",
    "        else:\n",
    "            dict = sentiment_data.iloc[a].to_dict()\n",
    "            tickers = dict[\"tickers\"].split(\"|\")\n",
    "            for ticker in to_remove:\n",
    "                if tickers is None:\n",
    "                    continue\n",
    "                elif ticker in tickers:\n",
    "                    tickers.remove(ticker)\n",
    "            if len(tickers) > 0:\n",
    "                for ticker in tickers:\n",
    "                    dict[\"tickers\"] = ticker\n",
    "                    single_tickers = single_tickers.append(dict, ignore_index=True)\n",
    "    return single_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main_frame = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set the Dates of Files to Construct the Naive Bayes Model\n",
    "## Feel Free to Change Dates Here for Using Existing Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reddit_dates = ['20211111', '20211114', '20211115', '20211116', '20211117', '20211118', '20211121', '20211123',\n",
    "                '20211124', '20211125', '20211128', '20211129', '20211130']\n",
    "nasdaq_dates = ['20211112', '20211115', '20211116', '20211117', '20211118', '20211119', '20211122', '20211124',\n",
    "                '20211125', '20211126', '20211129', '20211130', '20211201']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build Main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(reddit_dates)):\n",
    "    all_texts = combine_subreddit_texts_by_date(date=reddit_dates[i])\n",
    "    vader = VaderSentiment()\n",
    "    sentiment_data = vader.get_sentiment(dataframe=all_texts, show_text=True)\n",
    "    miner = TickersMining('input_data/nasdaq/nasdaq_stock_data_' + nasdaq_dates[i] + '.csv')\n",
    "\n",
    "    mined_tickers = miner.get_tickers(dataframe=sentiment_data)\n",
    "    sentiment_data['tickers'] = mined_tickers['tickers']\n",
    "\n",
    "    single_tickers = clean_tickers(sentiment_data)\n",
    "    single_tickers.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "    single_tickers.dropna(inplace=True)\n",
    "    grouped = single_tickers.groupby('tickers')\n",
    "    grouped = grouped.mean()\n",
    "    grouped['tickers'] = grouped.index\n",
    "    grouped.index.name = None\n",
    "    with_class = add_bearish_or_bullish_class(grouped,\n",
    "                                              pd.read_csv(\n",
    "                                                  'input_data/nasdaq/nasdaq_stock_data_' + nasdaq_dates[i] + '.csv'))\n",
    "\n",
    "    main_frame = main_frame.append(with_class, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set up X (features) and Y (Class) from Main DataFrame\n",
    "## X Contains Average Daily's Negative, Neutral, Positive, and Compound Sentiment Scores from VADER\n",
    "## X Example: [0.04300,0.18200,0.21150,0.01800]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = main_frame.drop(columns=['tickers', 'class', 'update_dt'])\n",
    "y = main_frame.drop(columns=['negative', 'neutral', 'positive', 'compound', 'tickers', 'update_dt'])\n",
    "\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Number of mislabeled points out of a total 894 points : 401'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Accuracy of predicting testing set: 0.5514541387024608'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\", line 1035, in _pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 144, in cmd_step_over\n",
      "    if _is_inside_jupyter_cell(frame, pydb):\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 209, in _is_inside_jupyter_cell\n",
      "    if is_cell_filename(filename):\n",
      "  File \"C:\\Users\\nlisichenok\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\213.5744.248\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\", line 220, in is_cell_filename\n",
      "    ipython_shell = get_ipython()\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "model = gnb.fit(x_train, y_train.ravel())\n",
    "y_pred = model.predict(x_test)\n",
    "counter = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i][0]:\n",
    "        counter = counter + 1\n",
    "        \n",
    "display(\"Number of mislabeled points out of a total %d points : %d\" % (x_test.shape[0], counter))\n",
    "display(\"Accuracy of predicting testing set: \" + str(1-(counter / x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predict Y from X via User Input Using Generated Naive Bayes Model. Example Included.\n",
    "## List Input is [Negative, Neutral, Positive, Compound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['bear'], dtype='<U4')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0.04400,0.01400,0.02100,0.18350]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Interface\n",
    "# Latest File Date Available Enter Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "latest_date_file_available = dt.date(2021, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from ipywidgets import interact\n",
    "import datetime\n",
    "\n",
    "# get yesterdays date\n",
    "yesterday = latest_date_file_available-datetime.timedelta(days=1)\n",
    "\n",
    "# get subset of main_frame only for that date\n",
    "main_frame_yesterday = main_frame.loc[main_frame['update_dt']==str(yesterday)]\n",
    "\n",
    "# get stock list from yesterday\n",
    "dates = main_frame['update_dt'].tolist()\n",
    "dates = list(dict.fromkeys(dates))\n",
    "\n",
    "list_of_dates = []\n",
    "for date in dates:\n",
    "    list_of_dates.append((date, date))\n",
    "\n",
    "# function for printing picture\n",
    "def select_date(date):\n",
    "    main_frame_date = main_frame.loc[main_frame['update_dt']==str(date)]\n",
    "\n",
    "    # get stock list from selected date\n",
    "    tickers = main_frame_date['tickers'].tolist()\n",
    "    tickers = list(dict.fromkeys(tickers))\n",
    "\n",
    "    list_of_tickers = []\n",
    "    for ticker in tickers:\n",
    "        list_of_tickers.append((ticker, ticker))\n",
    "    \n",
    "    # function for printing picture\n",
    "    interact(get_prediction, ticker=list_of_tickers)\n",
    "\n",
    "# function for printing picture\n",
    "def get_prediction(ticker):\n",
    "    \n",
    "    line = main_frame.loc[main_frame['tickers']==ticker].iloc[-1]\n",
    "    date_ = line[\"update_dt\"]\n",
    "    recommended_position = line[\"class\"]\n",
    "    \n",
    "    if recommended_position==\"bull\":\n",
    "        color = '\\033[92m' # GREEN\n",
    "        position = 'BULLISH'\n",
    "        file = 'input_data/naive_bayes_input/images/bullish.png'\n",
    "    else:\n",
    "        color = '\\033[91m' # RED\n",
    "        position = 'BEARISH'\n",
    "        file = 'input_data/naive_bayes_input/images/bearish.png'\n",
    "\n",
    "    print(\"Our model has a {}\\033[1m\\033[4m{}\\033[0m position on \\033[1m{}\\033[0m for {}\".format(color, position, ticker, date_))\n",
    "    display(Image(filename=file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Below predicts the latest data we can given the data available from the implemented Reddit's web scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive select bar for date\n",
    "interact(select_date, date=list_of_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}